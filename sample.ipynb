{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 10:47:47,935 - DEBUG - <ipython-input-1-87f9b1111895>:52 - Initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-10810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-18 10:47:47,941 - INFO - tf_logging.py:115 - Restoring parameters from ./model.ckpt-10810\n",
      "2019-02-18 10:47:47,965 - DEBUG - <ipython-input-1-87f9b1111895>:57 - restore from [./model.ckpt-10810]\n",
      "2019-02-18 10:47:48,169 - DEBUG - <ipython-input-1-87f9b1111895>:103 - ==============[江神子]==============\n",
      "2019-02-18 10:47:48,170 - DEBUG - <ipython-input-1-87f9b1111895>:104 - 江神子天月。一日清风无见去无。不似西山月雨处去人情处。且有西湖。莫用，今人，更人人。且不见。不用人、无是不来时去、何似不人来。更今事不\n",
      "2019-02-18 10:47:48,337 - DEBUG - <ipython-input-1-87f9b1111895>:103 - ==============[蝶恋花]==============\n",
      "2019-02-18 10:47:48,338 - DEBUG - <ipython-input-1-87f9b1111895>:104 - 蝶恋花人日春来何处处来风雨。且有无间不是春，无事。更是一声无去在来何许无人处。一里西花、不用无心处，只知何是是归情路。只教无处人年去处\n",
      "2019-02-18 10:47:48,504 - DEBUG - <ipython-input-1-87f9b1111895>:103 - ==============[渔家傲]==============\n",
      "2019-02-18 10:47:48,505 - DEBUG - <ipython-input-1-87f9b1111895>:104 - 渔家傲更得无人一笑处、何是。且知、一笑，人日春。且不为春处路路春风雨。莫是春情，人时、不似、不人无在去、一里一枝，不似东楼。只有清年一\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from random import choice\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "from model import Model\n",
    "\n",
    "from flags import parse_args\n",
    "FLAGS, unparsed = parse_args()\n",
    "\n",
    "FLAGS.text = 'QuanSongCi.txt'\n",
    "FLAGS.dictionary = 'embedding.npy'\n",
    "FLAGS.reverse_dictionary = 'reversed_embedding.npy'\n",
    "FLAGS.learning_rate = 0.01\n",
    "FLAGS.batch_size = 16\n",
    "FLAGS.num_steps = 10\n",
    "FLAGS.output_dir = './'\n",
    "verbose = True\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s', level=logging.DEBUG)\n",
    "\n",
    "\n",
    "with open(FLAGS.dictionary, encoding='utf-8') as inf:\n",
    "    dictionary = json.load(inf, encoding='utf-8')\n",
    "\n",
    "with open(FLAGS.reverse_dictionary, encoding='utf-8') as inf:\n",
    "    reverse_dictionary = json.load(inf, encoding='utf-8')\n",
    "\n",
    "\n",
    "reverse_list = [reverse_dictionary[str(i)]\n",
    "                for i in range(len(reverse_dictionary))]\n",
    "titles = ['江神子', '蝶恋花', '渔家傲']\n",
    "\n",
    "\n",
    "model = Model(learning_rate=FLAGS.learning_rate, batch_size=1, num_steps=1)\n",
    "model.build()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    summary_string_writer = tf.summary.FileWriter(FLAGS.output_dir, sess.graph)\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=5)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    logging.debug('Initialized')\n",
    "\n",
    "    try:\n",
    "        checkpoint_path = tf.train.latest_checkpoint(FLAGS.output_dir)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        logging.debug('restore from [{0}]'.format(checkpoint_path))\n",
    "\n",
    "    except Exception as E:\n",
    "        logging.debug('no check point found....')\n",
    "        print('E=',E)\n",
    "        exit(0)\n",
    "\n",
    "    for title in titles:\n",
    "        state = sess.run(model.state_tensor)\n",
    "        # feed title\n",
    "        for head in title:\n",
    "            input = utils.index_data(np.array([[head]]), dictionary)\n",
    "\n",
    "            feed_dict = {model.X: input,\n",
    "                         model.state_tensor: state,\n",
    "                         model.keep_prob: 1.0}\n",
    "\n",
    "            pred, state = sess.run(\n",
    "                [model.predictions, model.outputs_state_tensor], feed_dict=feed_dict)\n",
    "\n",
    "        sentence = title\n",
    "        word_index = pred[0].argsort()[-1]\n",
    "\n",
    "        # generate sample\n",
    "        for i in range(64):\n",
    "            feed_dict = {model.X: [[word_index]],\n",
    "                         model.state_tensor: state,\n",
    "                         model.keep_prob: 1.0}\n",
    "\n",
    "            pred, state = sess.run(\n",
    "                [model.predictions, model.outputs_state_tensor], feed_dict=feed_dict)\n",
    "\n",
    "            word_index = pred[0].argsort()[-1]\n",
    "            \n",
    "            tmp = pred[0].argsort()[-8:]\n",
    "#             print('tmp=', tmp)\n",
    "            word_index = choice(tmp)\n",
    "            if 2 == word_index:\n",
    "                word_index = pred[0].argsort()[-2]\n",
    "#             for i in pred[0].argsort()[-11:]:\n",
    "#                 print('reverse_list[i]=', reverse_list[i])\n",
    "            \n",
    "            word = np.take(reverse_list, word_index)\n",
    "            sentence = sentence + word\n",
    "\n",
    "\n",
    "        logging.debug('==============[{0}]=============='.format(title))\n",
    "        logging.debug(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
